"""
Ø§Ø®ØªØ¨Ø§Ø± Ø£Ø¯Ø§Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØªÙ‘Ø§Ø¨ - Writer Extraction Performance Testing
ÙŠÙ‚ÙŠØ³: Precision, Recall, F1-Score, Fuzzy Matching Accuracy
"""

import json
import time
import numpy as np
from typing import List, Dict, Set
from pathlib import Path
import logging
import sys

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø¬Ø°Ø±ÙŠ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹
sys.path.insert(0, str(Path(__file__).parent.parent))

from writer_manager import WriterManager

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
RESULTS_DIR = Path("test_results")
RESULTS_DIR.mkdir(exist_ok=True)


class WriterExtractionTester:
    """Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø§Ù…Ù„ Ù„Ø£Ø¯Ø§Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØªÙ‘Ø§Ø¨"""

    def __init__(self):
        self.writer_manager = WriterManager(db_folder="test_writers_db")
        self.test_documents = []
        self.results = {
            'extraction_results': [],
            'fuzzy_matching_results': [],
            'precision_scores': [],
            'recall_scores': [],
            'f1_scores': [],
            'processing_times': []
        }

    def load_test_documents(self, documents_file: str = None):
        """
        ØªØ­Ù…ÙŠÙ„ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ Ø§Ù„ÙƒØªÙ‘Ø§Ø¨ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠÙŠÙ†

        ØµÙŠØºØ© Ø§Ù„Ù…Ù„Ù JSON:
        [
            {
                "document_name": "article1.pdf",
                "document_path": "test_data/article1.pdf",
                "ground_truth_writers": [
                    "Ù…Ø­Ù…Ø¯ Ø£Ø­Ù…Ø¯",
                    "Sara Johnson"
                ]
            }
        ]
        """
        if documents_file and Path(documents_file).exists():
            with open(documents_file, 'r', encoding='utf-8') as f:
                self.test_documents = json.load(f)
        else:
            # Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…ÙˆØ°Ø¬ÙŠØ©
            self.test_documents = self._generate_sample_data()

        logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(self.test_documents)} Ù…Ø³ØªÙ†Ø¯ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±")
        return self.test_documents

    def _generate_sample_data(self) -> List[Dict]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…ÙˆØ°Ø¬ÙŠØ©"""
        return [
            {
                "document_name": "sample_article.pdf",
                "document_path": "test_data/sample_article.pdf",
                "ground_truth_writers": []  # ÙŠØ¬Ø¨ Ù…Ù„Ø¤Ù‡ ÙŠØ¯ÙˆÙŠÙ‹Ø§
            }
        ]

    def extract_writers_from_document(self, document_path: str, document_name: str) -> List[str]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØªÙ‘Ø§Ø¨ Ù…Ù† Ù…Ø³ØªÙ†Ø¯

        Returns:
            Ù‚Ø§Ø¦Ù…Ø© Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙƒØªÙ‘Ø§Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
        """
        start_time = time.time()

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØªÙ‘Ø§Ø¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… WriterManager
        if document_path.endswith('.pdf'):
            writer_names = self.writer_manager.extract_writer_names_from_pdf(document_path)
        else:
            # Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†ØµÙŠØ©
            with open(document_path, 'r', encoding='utf-8') as f:
                text = f.read()
            writer_names = self.writer_manager.extract_writer_names(text)

        processing_time = time.time() - start_time
        self.results['processing_times'].append({
            'document': document_name,
            'time': processing_time
        })

        return writer_names

    def calculate_metrics(self, predicted: Set[str], ground_truth: Set[str]) -> Dict[str, float]:
        """
        Ø­Ø³Ø§Ø¨ Precision, Recall, F1-Score

        Precision = TP / (TP + FP)
        Recall = TP / (TP + FN)
        F1 = 2 * (Precision * Recall) / (Precision + Recall)
        """
        if len(predicted) == 0 and len(ground_truth) == 0:
            return {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}

        # True Positives: Ø§Ø³ØªØ®Ø±Ø§Ø¬Ø§Øª ØµØ­ÙŠØ­Ø©
        tp = len(predicted & ground_truth)

        # False Positives: Ø§Ø³ØªØ®Ø±Ø§Ø¬Ø§Øª Ø®Ø§Ø·Ø¦Ø©
        fp = len(predicted - ground_truth)

        # False Negatives: ÙƒØªÙ‘Ø§Ø¨ Ù…ÙÙ‚ÙˆØ¯ÙˆÙ†
        fn = len(ground_truth - predicted)

        # Ø­Ø³Ø§Ø¨ Precision
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0

        # Ø­Ø³Ø§Ø¨ Recall
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0

        # Ø­Ø³Ø§Ø¨ F1-Score
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0

        return {
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'tp': tp,
            'fp': fp,
            'fn': fn
        }

    def test_fuzzy_matching(self, test_pairs: List[Dict] = None):
        """
        Ø§Ø®ØªØ¨Ø§Ø± Ø¯Ù‚Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠØ©

        test_pairs format:
        [
            {
                "name1": "Ù…Ø­Ù…Ø¯ Ø¹Ù„ÙŠ",
                "name2": "Ù…Ø­Ù…Ø¯ Ø¹Ù„ÙŠ Ø£Ø­Ù…Ø¯",
                "should_match": True
            }
        ]
        """
        if test_pairs is None:
            test_pairs = self._generate_fuzzy_test_pairs()

        logger.info("\n" + "="*80)
        logger.info("Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠØ©")
        logger.info("="*80)

        correct_matches = 0
        total_pairs = len(test_pairs)

        thresholds = [0.70, 0.75, 0.80, 0.85, 0.90, 0.95]
        threshold_results = {th: {'correct': 0, 'incorrect': 0} for th in thresholds}

        for pair in test_pairs:
            name1 = pair['name1']
            name2 = pair['name2']
            should_match = pair['should_match']

            similarity = self.writer_manager._calculate_name_similarity(name1, name2)

            logger.debug(f"{name1} vs {name2}: similarity={similarity:.3f}, expected={should_match}")

            # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ Ø¹ØªØ¨Ø§Øª Ù…Ø®ØªÙ„ÙØ©
            for threshold in thresholds:
                predicted_match = similarity >= threshold
                is_correct = (predicted_match == should_match)

                if is_correct:
                    threshold_results[threshold]['correct'] += 1
                else:
                    threshold_results[threshold]['incorrect'] += 1

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø© Ù„ÙƒÙ„ Ø¹ØªØ¨Ø©
        logger.info("\nÙ†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠØ©:")
        logger.info("-" * 60)
        logger.info(f"{'Ø§Ù„Ø¹ØªØ¨Ø©':<10} {'ØµØ­ÙŠØ­':<10} {'Ø®Ø§Ø·Ø¦':<10} {'Ø§Ù„Ø¯Ù‚Ø© (%)':<15}")
        logger.info("-" * 60)

        best_threshold = None
        best_accuracy = 0

        for threshold in thresholds:
            correct = threshold_results[threshold]['correct']
            incorrect = threshold_results[threshold]['incorrect']
            accuracy = (correct / total_pairs) * 100

            logger.info(f"{threshold:<10.2f} {correct:<10} {incorrect:<10} {accuracy:<15.2f}")

            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_threshold = threshold

            self.results['fuzzy_matching_results'].append({
                'threshold': threshold,
                'accuracy': accuracy / 100,
                'correct': correct,
                'incorrect': incorrect
            })

        logger.info("-" * 60)
        logger.info(f"Ø£ÙØ¶Ù„ Ø¹ØªØ¨Ø©: {best_threshold} Ø¨Ø¯Ù‚Ø© {best_accuracy:.2f}%")

        return best_threshold, best_accuracy

    def _generate_fuzzy_test_pairs(self) -> List[Dict]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø²ÙˆØ§Ø¬ Ø§Ø®ØªØ¨Ø§Ø± Ù„Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠØ©"""
        return [
            # Ø£Ø²ÙˆØ§Ø¬ ÙŠØ¬Ø¨ Ø£Ù† ØªØªØ·Ø§Ø¨Ù‚
            {"name1": "Ù…Ø­Ù…Ø¯ Ø£Ø­Ù…Ø¯", "name2": "Ù…Ø­Ù…Ø¯ Ø£Ø­Ù…Ø¯ Ø¹Ù„ÙŠ", "should_match": True},
            {"name1": "Sara Johnson", "name2": "Sara J. Johnson", "should_match": True},
            {"name1": "Dr. Ahmed Hassan", "name2": "Ahmed Hassan", "should_match": True},
            {"name1": "Ø¹Ù„ÙŠ Ù…Ø­Ù…Ø¯", "name2": "Ù…Ø­Ù…Ø¯ Ø¹Ù„ÙŠ", "should_match": True},
            {"name1": "John Smith", "name2": "Jon Smith", "should_match": True},  # Ø®Ø·Ø£ Ø¥Ù…Ù„Ø§Ø¦ÙŠ

            # Ø£Ø²ÙˆØ§Ø¬ Ù„Ø§ ÙŠØ¬Ø¨ Ø£Ù† ØªØªØ·Ø§Ø¨Ù‚
            {"name1": "Ù…Ø­Ù…Ø¯ Ø£Ø­Ù…Ø¯", "name2": "Ø£Ø­Ù…Ø¯ Ù…Ø­Ù…ÙˆØ¯", "should_match": False},
            {"name1": "Sara Johnson", "name2": "Sarah Williams", "should_match": False},
            {"name1": "Ahmed Ali", "name2": "Mohamed Ali", "should_match": False},
            {"name1": "John Smith", "name2": "Jane Smith", "should_match": False},
            {"name1": "Ø¹Ù„ÙŠ Ø­Ø³Ù†", "name2": "Ø­Ø³ÙŠÙ† Ø¹Ù„ÙŠ", "should_match": False},

            # Ø­Ø§Ù„Ø§Øª Ø­Ø¯ÙŠØ©
            {"name1": "Dr. Mohamed", "name2": "Prof. Mohamed", "should_match": True},
            {"name1": "Ø£.Ø¯. Ù…Ø­Ù…Ø¯", "name2": "Ø¯. Ù…Ø­Ù…Ø¯", "should_match": True},
        ]

    def test_extraction_techniques(self, test_pdf: str = None):
        """
        Ø§Ø®ØªØ¨Ø§Ø± Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
        """
        if not test_pdf or not Path(test_pdf).exists():
            logger.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù PDF Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±")
            return

        logger.info("\n" + "="*80)
        logger.info("Ù…Ù‚Ø§Ø±Ù†Ø© ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬")
        logger.info("="*80)

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
        blocks = self.writer_manager.extract_blocks_from_pdf(test_pdf)

        if blocks:
            # 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ© (Layout Analysis)
            headline_blocks = self.writer_manager.identify_headline_blocks(blocks)
            layout_writers = self.writer_manager.extract_byline_patterns(blocks)

            # 2. NER
            ner_writers = self.writer_manager.extract_names_with_ner(blocks)

            # 3. Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„
            all_writers = self.writer_manager.extract_writer_names_from_pdf(test_pdf)

            logger.info(f"\nØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ©: {len(layout_writers)} ÙƒØ§ØªØ¨")
            logger.info(f"  {layout_writers}")

            logger.info(f"\nNER: {len(ner_writers)} ÙƒØ§ØªØ¨")
            logger.info(f"  {ner_writers}")

            logger.info(f"\nØ§Ù„Ù†Ù‡Ø¬ Ø§Ù„Ù‡Ø¬ÙŠÙ† (Ø§Ù„ÙƒÙ„): {len(all_writers)} ÙƒØ§ØªØ¨")
            logger.info(f"  {all_writers}")

            return {
                'layout': layout_writers,
                'ner': ner_writers,
                'hybrid': all_writers
            }

    def run_tests(self):
        """ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØªÙ‘Ø§Ø¨"""
        logger.info("="*80)
        logger.info("Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØªÙ‘Ø§Ø¨")
        logger.info("="*80)

        # 1. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª
        for idx, test_doc in enumerate(self.test_documents, 1):
            document_name = test_doc['document_name']
            document_path = test_doc['document_path']
            ground_truth = set(test_doc.get('ground_truth_writers', []))

            logger.info(f"\n[{idx}/{len(self.test_documents)}] Ù…Ø¹Ø§Ù„Ø¬Ø©: {document_name}")

            if not Path(document_path).exists():
                logger.warning(f"  âš ï¸  Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {document_path}")
                continue

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØªÙ‘Ø§Ø¨
            extracted_writers = self.extract_writers_from_document(document_path, document_name)
            predicted = set(extracted_writers)

            logger.info(f"  Ø§Ù„ÙƒØªÙ‘Ø§Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ÙˆÙ†: {extracted_writers}")
            logger.info(f"  Ø§Ù„ÙƒØªÙ‘Ø§Ø¨ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠÙˆÙ†: {list(ground_truth)}")

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            if ground_truth:
                metrics = self.calculate_metrics(predicted, ground_truth)

                self.results['precision_scores'].append(metrics['precision'])
                self.results['recall_scores'].append(metrics['recall'])
                self.results['f1_scores'].append(metrics['f1'])

                logger.info(f"  Precision: {metrics['precision']:.3f}")
                logger.info(f"  Recall: {metrics['recall']:.3f}")
                logger.info(f"  F1-Score: {metrics['f1']:.3f}")

                self.results['extraction_results'].append({
                    'document': document_name,
                    'predicted': list(predicted),
                    'ground_truth': list(ground_truth),
                    'metrics': metrics
                })
            else:
                logger.warning("  âš ï¸  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø±Ø¬Ø¹ÙŠØ© Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©")

        # 2. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠØ©
        self.test_fuzzy_matching()

        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù…Ù„Ø®Øµ
        logger.info("\n" + "="*80)
        logger.info("Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©")
        logger.info("="*80)
        self.print_summary()

        return self.results

    def print_summary(self):
        """Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
        print("\nğŸ“Š Ù…Ù„Ø®Øµ Ø£Ø¯Ø§Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØªÙ‘Ø§Ø¨\n")

        if self.results['precision_scores']:
            avg_precision = np.mean(self.results['precision_scores']) * 100
            avg_recall = np.mean(self.results['recall_scores']) * 100
            avg_f1 = np.mean(self.results['f1_scores']) * 100

            print("Ø¬Ø¯ÙˆÙ„: Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬")
            print("-" * 50)
            print(f"{'Ø§Ù„Ù…Ù‚ÙŠØ§Ø³':<20} {'Ø§Ù„Ù…ØªÙˆØ³Ø· (%)':<15}")
            print("-" * 50)
            print(f"{'Precision':<20} {avg_precision:>10.2f}%")
            print(f"{'Recall':<20} {avg_recall:>10.2f}%")
            print(f"{'F1-Score':<20} {avg_f1:>10.2f}%")
            print("-" * 50)

        if self.results['processing_times']:
            times = [t['time'] for t in self.results['processing_times']]
            avg_time = np.mean(times)
            print(f"\nÙ…ØªÙˆØ³Ø· Ø²Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {avg_time:.3f} Ø«Ø§Ù†ÙŠØ©")
            print(f"Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù…Ø®ØªØ¨Ø±Ø©: {len(self.test_documents)}")

    def save_results(self, filename: str = "writer_extraction_results.json"):
        """Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ Ù…Ù„Ù JSON"""
        output_path = RESULTS_DIR / filename

        results_to_save = {
            'avg_precision': float(np.mean(self.results['precision_scores'])) if self.results['precision_scores'] else None,
            'avg_recall': float(np.mean(self.results['recall_scores'])) if self.results['recall_scores'] else None,
            'avg_f1': float(np.mean(self.results['f1_scores'])) if self.results['f1_scores'] else None,
            'num_documents': len(self.test_documents),
            'fuzzy_matching_results': self.results['fuzzy_matching_results'],
            'extraction_results': self.results['extraction_results'],
            'processing_times': self.results['processing_times']
        }

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results_to_save, f, ensure_ascii=False, indent=2)

        logger.info(f"\nâœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: {output_path}")
        return output_path


def main():
    """Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    print("\n" + "="*80)
    print("âœï¸  Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØªÙ‘Ø§Ø¨")
    print("="*80 + "\n")

    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    tester = WriterExtractionTester()

    # ØªØ­Ù…ÙŠÙ„ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    tester.load_test_documents("test_data/writer_test_documents.json")

    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    results = tester.run_tests()

    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    tester.save_results()

    print("\nâœ… Ø§ÙƒØªÙ…Ù„Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")


if __name__ == "__main__":
    main()
